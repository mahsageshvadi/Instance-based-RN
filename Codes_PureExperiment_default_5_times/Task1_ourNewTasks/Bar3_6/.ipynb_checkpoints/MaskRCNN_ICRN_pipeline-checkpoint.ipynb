{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88bff7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "\n",
    "sys.path.append(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a29d690",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "243aa2d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Configure'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23146/1750696130.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mICRNConfigure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmrcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mDataset_generator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGenerateOneBarChart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/PaperCodes/Comparison/Instance-based-RN/Codes_PureExperiment_default_5_times/Task1_ourNewTasks/Bar3_6/Dataset_generator.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mConfigure\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMakeDir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Configure'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import mrcnn.model as modellib\n",
    "\n",
    "\n",
    "import ICRNConfigure\n",
    "from mrcnn.config import Config\n",
    "from Dataset_generator import GenerateOneBarChart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e793a6ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23146/3011364377.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mShapesConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \"\"\"Configuration for training on the toy shapes dataset.\n\u001b[1;32m      3\u001b[0m     \u001b[0mDerives\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mbase\u001b[0m \u001b[0mConfig\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0moverrides\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0mspecific\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtoy\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \"\"\"\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Config' is not defined"
     ]
    }
   ],
   "source": [
    "class ShapesConfig(Config):\n",
    "    \"\"\"Configuration for training on the toy shapes dataset.\n",
    "    Derives from the base Config class and overrides values specific\n",
    "    to the toy shapes dataset.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"CQA\"\n",
    "\n",
    "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
    "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 8\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 1  # background + 3 shapes\n",
    "\n",
    "    # Use small images for faster training. Set the limits of the small side\n",
    "    # the large side, and that determines the image shape.\n",
    "    IMAGE_MIN_DIM = 128\n",
    "    IMAGE_MAX_DIM = 128\n",
    "\n",
    "    # Use smaller anchors because our image and objects are small\n",
    "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)  # anchor side in pixels\n",
    "\n",
    "    # Reduce training ROIs per image because the images are small and have\n",
    "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
    "    TRAIN_ROIS_PER_IMAGE = 32\n",
    "\n",
    "    # Use a small epoch since the data is simple\n",
    "    STEPS_PER_EPOCH = 100\n",
    "\n",
    "    # use small validation steps since the epoch is small\n",
    "    VALIDATION_STEPS = 5\n",
    "    \n",
    "maskrcnnconfig = ShapesConfig()\n",
    "maskrcnnconfig.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1a5684d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "RCNNMODEL_DIR = os.path.join(ROOT_DIR, \"logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569b2026",
   "metadata": {},
   "source": [
    "# load Mask RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dff920ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from  /home/mahsa.geshvadi001/projects/ICRN/Mask-RCNN-TF2/logs/cqa20230313T1326/mask_rcnn_cqa_0060.h5\n",
      "Re-starting from epoch 60\n"
     ]
    }
   ],
   "source": [
    "class InferenceConfig(ShapesConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "# Recreate the model in inference mode\n",
    "maskrcnn_model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=RCNNMODEL_DIR)\n",
    "\n",
    "maskrcnn_model_path = maskrcnn_model.find_last()\n",
    "\n",
    "# Load trained weights\n",
    "print(\"Loading weights from \", maskrcnn_model_path)\n",
    "maskrcnn_model.load_weights(maskrcnn_model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917c0d50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4c1cd92",
   "metadata": {},
   "source": [
    "# Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e3c52a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "ICRN_config = ICRNConfigure.Config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5fc95411",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segmented_image(x1, y1, x2, y2, image):\n",
    "    \n",
    "    segment = image[x1: y1, x2 : y2]\n",
    "    new_image = np.ones(shape=(image.shape[0], image.shape[1], image.shape[2]))\n",
    "    new_image[x1: y1, x2 : y2] = segment\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7162355d",
   "metadata": {},
   "source": [
    "Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a9b947a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_num = 10\n",
    "min_num_obj = 3\n",
    "max_num_obj = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c33c1e0",
   "metadata": {},
   "source": [
    "Generate Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "40382339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segmented_image(x1, y1, x2, y2, image):\n",
    "    \n",
    "    segment = image[x1: y1, x2 : y2]\n",
    "    new_image = np.ones(shape=(image.shape[0], image.shape[1], image.shape[2]))\n",
    "    new_image[x1: y1, x2 : y2] = segment\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "68c95b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resetting the folder..... testDataset\n"
     ]
    }
   ],
   "source": [
    "ICRNConfigure.MakeDir('testDataset')\n",
    "ICRNConfigure.ClearDir('testDataset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7aaaa614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveImage(image, featureVector, i):\n",
    "\n",
    "    file_gt = open('testDataset/ground_truth.txt', 'w')\n",
    "    file_pair_gt = open('testDataset/pair_ground_truth.txt','w')\n",
    "    cv2.imwrite('testDataset/' + ICRN_config.chartName.format(i), image * 255)\n",
    "    \n",
    "    for t in range(len(featureVector)):\n",
    "        file_gt.write(\"%.6f\\t\" % (featureVector[t]))\n",
    "                \n",
    "    for t in range(ICRN_config.max_obj_num - len(featureVector)):\n",
    "        file_gt.write(\"0.00\\t\")\n",
    "        file_gt.write(\"\\n\")\n",
    "\n",
    "    for t in range(len(featureVector) - 1):\n",
    "            file_pair_gt.write(\"{} {} {}\\n\".format(ICRN_config.subChartName.format(i, t),\n",
    "                                                       ICRN_config.subChartName.format(i, t + 1),\n",
    "                                                       featureVector[t+1] / featureVector[t]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4026b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2b8f116b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_images = np.ones((ICRN_config.max_obj_num, image_num, ICRN_config.image_height, ICRN_config.image_width, 3), dtype='float32')\n",
    "_labels = []\n",
    "number_of_bars = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "23a26f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1 images\n",
      "image                    shape: (100, 100, 3)         min:    0.07347  max:    1.00000  float64\n",
      "molded_images            shape: (1, 128, 128, 3)      min: -123.62653  max: -102.90062  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max:  128.00000  float64\n",
      "anchors                  shape: (1, 4092, 4)          min:   -0.71267  max:    1.20874  float32\n",
      "Processing 1 images\n",
      "image                    shape: (100, 100, 3)         min:    0.02444  max:    1.00000  float64\n",
      "molded_images            shape: (1, 128, 128, 3)      min: -123.54317  max: -102.90061  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max:  128.00000  float64\n",
      "anchors                  shape: (1, 4092, 4)          min:   -0.71267  max:    1.20874  float32\n",
      "Processing 1 images\n",
      "image                    shape: (100, 100, 3)         min:    0.06778  max:    1.00000  float64\n",
      "molded_images            shape: (1, 128, 128, 3)      min: -123.53256  max: -102.90089  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max:  128.00000  float64\n",
      "anchors                  shape: (1, 4092, 4)          min:   -0.71267  max:    1.20874  float32\n",
      "Processing 1 images\n",
      "image                    shape: (100, 100, 3)         min:    0.03535  max:    1.00000  float64\n",
      "molded_images            shape: (1, 128, 128, 3)      min: -123.66306  max: -102.90070  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max:  128.00000  float64\n",
      "anchors                  shape: (1, 4092, 4)          min:   -0.71267  max:    1.20874  float32\n",
      "Processing 1 images\n",
      "image                    shape: (100, 100, 3)         min:    0.04148  max:    1.00000  float64\n",
      "molded_images            shape: (1, 128, 128, 3)      min: -123.65619  max: -102.90078  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max:  128.00000  float64\n",
      "anchors                  shape: (1, 4092, 4)          min:   -0.71267  max:    1.20874  float32\n",
      "Processing 1 images\n",
      "image                    shape: (100, 100, 3)         min:    0.00569  max:    1.00000  float64\n",
      "molded_images            shape: (1, 128, 128, 3)      min: -123.65575  max: -102.90154  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max:  128.00000  float64\n",
      "anchors                  shape: (1, 4092, 4)          min:   -0.71267  max:    1.20874  float32\n",
      "Processing 1 images\n",
      "image                    shape: (100, 100, 3)         min:    0.09477  max:    1.00000  float64\n",
      "molded_images            shape: (1, 128, 128, 3)      min: -123.44270  max: -102.90086  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max:  128.00000  float64\n",
      "anchors                  shape: (1, 4092, 4)          min:   -0.71267  max:    1.20874  float32\n",
      "Processing 1 images\n",
      "image                    shape: (100, 100, 3)         min:    0.10632  max:    1.00000  float64\n",
      "molded_images            shape: (1, 128, 128, 3)      min: -123.50452  max: -102.90106  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max:  128.00000  float64\n",
      "anchors                  shape: (1, 4092, 4)          min:   -0.71267  max:    1.20874  float32\n",
      "Processing 1 images\n",
      "image                    shape: (100, 100, 3)         min:    0.00222  max:    1.00000  float64\n",
      "molded_images            shape: (1, 128, 128, 3)      min: -123.65950  max: -102.90083  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max:  128.00000  float64\n",
      "anchors                  shape: (1, 4092, 4)          min:   -0.71267  max:    1.20874  float32\n",
      "Processing 1 images\n",
      "image                    shape: (100, 100, 3)         min:    0.00830  max:    1.00000  float64\n",
      "molded_images            shape: (1, 128, 128, 3)      min: -123.66286  max: -102.90103  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max:  128.00000  float64\n",
      "anchors                  shape: (1, 4092, 4)          min:   -0.71267  max:    1.20874  float32\n"
     ]
    }
   ],
   "source": [
    "for i in range(image_num):\n",
    "\n",
    "        image, _, featureVector = GenerateOneBarChart(\n",
    "                num=np.random.randint(min_num_obj, max_num_obj + 1))\n",
    "        \n",
    "        saveImage(image, featureVector, i)\n",
    "        featureVector = np.array(featureVector)\n",
    "\n",
    "        results = maskrcnn_model.detect([image], verbose=1)\n",
    "        r = results[0]\n",
    "        arr = r['rois']\n",
    "        segments_bbs = arr[arr[:,1].argsort()]\n",
    "\n",
    "        segments = []\n",
    "        for t in range(len(r['rois'])):\n",
    "            segments.append(get_segmented_image(segments_bbs[t][0],segments_bbs[t][2], \n",
    "                                                segments_bbs[t][1] , segments_bbs[t][3], image))\n",
    "            \n",
    "        subImages = [np.ones(shape=(ICRN_config.image_width,ICRN_config.image_width,3)) for i in range(ICRN_config.max_obj_num)]\n",
    "        for count in range(len(r['rois'])):\n",
    "            subImages[count] = segments[count]\n",
    "            \n",
    "        for t in range(ICRN_config.max_obj_num):\n",
    "            _images[t][i] = subImages[t]\n",
    "\n",
    "        number_of_bars.append(len(r['rois']))\n",
    "        \n",
    "        label = np.zeros(ICRN_config.max_obj_num, dtype='float32')\n",
    "        label[:len(featureVector)] = featureVector\n",
    "        _labels.append(label)\n",
    "        \n",
    "_labels = np.array(_labels, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5d49f6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = _images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "27b2549d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = [x_test[i] for i in range(ICRN_config.max_obj_num)]\n",
    "x_test.append(np.ones(image_num))\n",
    "input_test = [x_test[i] for i in range(ICRN_config.max_obj_num)]\n",
    "input_test.append(np.ones(input_test[0].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f13f9637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f393e0e5",
   "metadata": {},
   "source": [
    "# Predict the ratio with ICRN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d9393c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten,Input\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import SGD, Adam\n",
    "from non_local import non_local_block\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import time, argparse\n",
    "import pickle\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6fbe9e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Level1_Module():\n",
    "    input = Input(shape=(ICRN_config.image_height, ICRN_config.image_width, 3))\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(input)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
    "    x = non_local_block(x)   # non local block\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
    "    x = non_local_block(x)   # non local block\n",
    "    return Model(inputs=input, outputs=x)\n",
    "\n",
    "# Level2 module is to compute the ratio of a pair.\n",
    "# Level2 has one NON-LOCAL block.\n",
    "def Level2_Module(w,h,c):\n",
    "    print(\"Level2:\", w,h,c)\n",
    "\n",
    "    inputA = Input(shape=(w, h, c))\n",
    "    inputB = Input(shape=(w, h, c))\n",
    "\n",
    "    combined = keras.layers.concatenate([inputA, inputB])   # concatenate them.\n",
    "    z = Conv2D(64, (3, 3), activation='relu',padding='same')(combined)\n",
    "    z = Conv2D(64, (3, 3), activation='relu', padding='same')(z)\n",
    "    z = non_local_block(z)   # non local block\n",
    "    #\n",
    "    z = Flatten()(z)\n",
    "    z = Dense(256, activation=\"relu\")(z)\n",
    "    z = Dropout(0.5)(z)\n",
    "    z = Dense(1, activation=\"linear\")(z)  # output the ratio of this pair.\n",
    "\n",
    "    return Model(inputs=[inputA, inputB], outputs=z)\n",
    "\n",
    "\n",
    "\n",
    "# IRN_m is final network to estimate the ratio vectors from multiple input instances.\n",
    "def Build_IRN_m_Network():\n",
    "    # input layers.\n",
    "    input_layers = []\n",
    "    # the first 'obj_num' inputs are corresponding to the input sub-charts.\n",
    "    for i in range(ICRN_config.max_obj_num):\n",
    "        input = Input(shape=(ICRN_config.image_height, ICRN_config.image_width, 3), name=\"input_{}\".format(i))\n",
    "        input_layers.append(input)\n",
    "\n",
    "    # The last input layer is used for representing R1=(o1/o1)=1.0 which is just a constant.\n",
    "    # Here, I would use an extra input layer which is 1-dim and always equal to 1.0 rather than directly using a contant.\n",
    "    # It makes same effect and can avoid some strange compile errors. (I only use TensorFlow before, not way familiar to Keras.)\n",
    "    R1_one_input = Input(shape=(1,),name=\"input_constant_scalar1\",dtype='float32')   # always equal to 1.0.\n",
    "    input_layers.append(R1_one_input)\n",
    "\n",
    "    # First extract individual features.\n",
    "    individual_features = []\n",
    "    level1 = Level1_Module()  # build a level1 module\n",
    "    for i in range(ICRN_config.max_obj_num):\n",
    "        x = level1(input_layers[i])\n",
    "        individual_features.append(x)\n",
    "\n",
    "    # Use a Level2 module to predict pairwise ratios.\n",
    "    level2 = Level2_Module(w=int(individual_features[0].shape[1]),\n",
    "                           h=int(individual_features[0].shape[2]),\n",
    "                           c=int(individual_features[0].shape[3]))\n",
    "\n",
    "    ratio_p_layers = [R1_one_input]   # pairwise ratio vector. put in' R1=(o1/o1)=1.0 '.\n",
    "    for i in range(ICRN_config.max_obj_num-1): # compute the ratio of each neighbor pair.\n",
    "        x = level2(inputs = [individual_features[i], individual_features[i+1]])\n",
    "        ratio_p_layers.append(x)\n",
    "\n",
    "    print(\"ratio_p_layers\", len(ratio_p_layers), ratio_p_layers[-1].shape)\n",
    "\n",
    "    # Compute the ratios relative to the first object by using MULTIPLY() operation.\n",
    "    ratio_layers = [R1_one_input]  # put in R1=1.0.\n",
    "    i = 1\n",
    "    while i<len(ratio_p_layers):\n",
    "        x = keras.layers.Multiply()(ratio_p_layers[:i+1])   # R1*R2*...Ri\n",
    "        i+=1\n",
    "        ratio_layers.append(x)\n",
    "\n",
    "    # divide the maxinum of 'ratio_layers' to get the final results.\n",
    "    max = keras.layers.maximum(ratio_layers)\n",
    "    z = keras.layers.concatenate(ratio_layers)\n",
    "    z = keras.layers.Lambda(lambda x: x[0]/x[1])([z, max])\n",
    "\n",
    "    print(\"output layer: \", z.shape)\n",
    "\n",
    "    return Model(inputs=input_layers, outputs=z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aae73648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level2: 12 12 64\n",
      "ratio_p_layers 6 (None, 1)\n",
      "output layer:  (None, 6)\n"
     ]
    }
   ],
   "source": [
    "model = Build_IRN_m_Network()\n",
    "m_optimizer = Adam(0.0001)\n",
    "model.compile(loss='mse', optimizer=m_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "00216e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model_IcRN_onTrain_0.00010191364316851832.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "90f57a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_Y = model.predict(x=input_test, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "acf279c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.73373264, 0.25762898, 1.        , 0.527681  , 0.35504785,\n",
       "        0.        ],\n",
       "       [0.2905684 , 1.        , 0.5370313 , 0.72743607, 0.3787142 ,\n",
       "        0.        ],\n",
       "       [0.26805046, 1.        , 0.6335383 , 0.20799974, 0.        ,\n",
       "        0.        ],\n",
       "       [0.6147509 , 1.        , 0.8618479 , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.5976253 , 1.        , 0.65843636, 0.65841496, 0.        ,\n",
       "        0.        ],\n",
       "       [1.        , 0.38676196, 0.32417902, 0.8045689 , 0.        ,\n",
       "        0.        ],\n",
       "       [0.6109523 , 0.57683975, 0.62685907, 1.        , 0.24313599,\n",
       "        0.8364736 ],\n",
       "       [0.4305235 , 0.20170055, 0.44195256, 0.4044045 , 1.        ,\n",
       "        0.8248069 ],\n",
       "       [0.94045705, 1.        , 0.14257362, 0.7232985 , 0.        ,\n",
       "        0.        ],\n",
       "       [0.21849032, 1.        , 0.3143898 , 0.48881963, 0.549113  ,\n",
       "        0.67480296]], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "22d4db7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(image_num):\n",
    "\n",
    "        predict_Y[n][number_of_bars[n]: 6] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "88c2b5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = _labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8deb4645",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLAE = np.log2(sklearn.metrics.mean_absolute_error( predict_Y * 100, y * 100) + .125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bf1910e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4228321562144821"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db528d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d706a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4789c101",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
